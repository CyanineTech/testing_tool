import os
import sys
import argparse
import random
import time
import requests
import logging
from datetime import datetime, timedelta
from openpyxl import load_workbook
from typing import Dict, List, Optional, Set, Tuple, Union, Any
from configparser import ConfigParser
import signal
from dataclasses import dataclass, field
from functools import wraps
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import json

# ==============================
# å¸¸é‡å®šä¹‰
# ==============================
VALID_RULES = {1, 2}
REQUIRED_EXCEL_COLUMNS = {'id', 'alias_kept'}
REQUIRED_CONFIG_SECTIONS = ['base', 'service', 'map', 'business', 'task', 'excel', 'log']
REQUIRED_CONFIG_KEYS = {
    'base': ['account', 'password', 'token'],
    'service': ['host', 'port'],
    'map': ['scene_id'],
    'business': ['rule', 'areas'],
    'task': ['locations'],
    'excel': ['xlsx_path'],
    'log': ['debug', 'log_file']
}
TARGET_ERROR_ID = 50421021  # ç›®æ ‡error_idï¼ˆä»…è¯¥IDè§†ä¸ºæˆåŠŸï¼‰
MAX_CONTINUOUS_FAILURES = 5  # æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
DEFAULT_ERROR_INFO = "æ— è¯¦ç»†é”™è¯¯ä¿¡æ¯"  # é»˜è®¤é”™è¯¯ä¿¡æ¯

# ==============================
# æ•°æ®ç±»å®šä¹‰
# ==============================
@dataclass
class TaskConfig:
    """ä»»åŠ¡é…ç½®æ•°æ®ç±»ï¼ˆå®Œå…¨ä»config.iniè¯»å–ï¼‰"""
    # [base] èŠ‚
    account: str
    password: str
    token: str
    
    # [service] èŠ‚
    host: str
    port: int
    
    # [map] èŠ‚
    scene_id: int
    
    # [business] èŠ‚
    rule: int
    areas: List[str]
    fixed_store: str
    
    # [task] èŠ‚
    locations: List[str]
    
    # [excel] èŠ‚
    xlsx_path: str
    sheet_name: Optional[str]
    
    # [log] èŠ‚
    debug: bool
    log_file: str
    
    # [request] èŠ‚ï¼ˆé»˜è®¤é…ç½®ç”Ÿæ•ˆï¼‰
    request_timeout: float = 15.0
    retry_count: int = 0
    retry_delay: float = 1.0

@dataclass
class LocationInfo:
    """ä½ç½®ä¿¡æ¯æ•°æ®ç±»"""
    location_id: str
    area: str
    number: int
    full_area: str

@dataclass
class TaskStats:
    """ä»»åŠ¡ç»Ÿè®¡æ•°æ®ç±»"""
    success: int = 0
    fail: int = 0
    total: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    valid_areas: List[str] = field(default_factory=list)
    total_task_count: int = 0
    skipped: int = 0  # è·³è¿‡çš„ä»»åŠ¡æ•°
    continuous_failures: int = 0  # è¿ç»­å¤±è´¥æ¬¡æ•°

# ==============================
# å…¨å±€å˜é‡
# ==============================
global_config: Optional[TaskConfig] = None
task_stats = TaskStats()
resource_handles: Dict[str, Optional[object]] = {"excel_workbook": None, "http_session": None}
is_running = False
console_logger: Optional[logging.Logger] = None
file_logger: Optional[logging.Logger] = None

# ==============================
# è£…é¥°å™¨
# ==============================
def exception_handler(return_value: Union[bool, List, Tuple, None] = False):
    """å¼‚å¸¸å¤„ç†è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                func_name = func.__name__
                # æ£€æŸ¥æ—¥å¿—æ˜¯å¦å·²åˆå§‹åŒ–
                if file_logger:
                    file_logger.error(f"å‡½æ•° {func_name} æ‰§è¡Œå¼‚å¸¸", exc_info=True)
                if console_logger:
                    console_logger.error(f"âŒ {func_name} æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
                else:
                    print(f"âŒ {func_name} æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
                return return_value
        return wrapper
    return decorator

# ==============================
# æ—¥å¿—ç›¸å…³å‡½æ•°
# ==============================
def init_loggers(log_file: str, debug: bool):
    """åˆå§‹åŒ–åŒæ—¥å¿—ï¼šæ§åˆ¶å°ï¼ˆç®€åŒ–ï¼‰+ æ–‡ä»¶ï¼ˆè¯¦ç»†ï¼‰"""
    global console_logger, file_logger

    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    log_dir = os.path.dirname(log_file)
    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # 1. æ–‡ä»¶æ—¥å¿—ï¼ˆè¯¦ç»†ï¼Œä¿ç•™æ‰€æœ‰ä¿¡æ¯ï¼‰
    file_handler = logging.FileHandler(log_file, encoding="utf-8", mode="a")
    file_formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    file_handler.setFormatter(file_formatter)
    file_logger = logging.getLogger("TaskFileLogger")
    file_logger.addHandler(file_handler)
    file_logger.setLevel(logging.DEBUG if debug else logging.INFO)
    file_logger.propagate = False

    # 2. æ§åˆ¶å°æ—¥å¿—ï¼ˆç®€åŒ–ï¼Œä»…å…³é”®ä¿¡æ¯ï¼‰
    console_handler = logging.StreamHandler(sys.stdout)
    console_formatter = logging.Formatter("%(message)s")
    console_handler.setFormatter(console_formatter)
    console_logger = logging.getLogger("TaskConsoleLogger")
    console_logger.addHandler(console_handler)
    console_logger.setLevel(logging.INFO)
    console_logger.propagate = False

    if file_logger:
        file_logger.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

def load_log_config_from_ini(config_path: str) -> Tuple[Optional[str], Optional[bool]]:
    """ä»…åŠ è½½æ—¥å¿—ç›¸å…³é…ç½®ï¼ˆç”¨äºåˆå§‹åŒ–æ—¥å¿—ï¼‰"""
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼")
        return None, None

    try:
        config = ConfigParser()
        config.optionxform = str
        config.read(config_path, encoding="utf-8")

        # æ£€æŸ¥logèŠ‚æ˜¯å¦å­˜åœ¨
        if not config.has_section("log"):
            print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘ [log] èŠ‚ï¼")
            return None, None

        # è¯»å–æ—¥å¿—é…ç½®
        log_file = config.get("log", "log_file", fallback=None)
        debug_str = config.get("log", "debug", fallback=None)

        if not log_file:
            print(f"âŒ [log] èŠ‚ç¼ºå°‘ log_file é…ç½®ï¼")
            return None, None

        debug = parse_ini_bool(debug_str) if debug_str is not None else False

        return log_file.strip(), debug

    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—é…ç½®å¤±è´¥ï¼š{str(e)}")
        return None, None

# ==============================
# é…ç½®è§£æå·¥å…·å‡½æ•°
# ==============================
def parse_ini_list(value: str) -> List[str]:
    """è§£æINIåˆ—è¡¨é…ç½®ï¼ˆå»é‡ã€è¿‡æ»¤ç©ºå€¼ï¼‰"""
    if not value:
        return []
    return list(set([item.strip() for item in value.split(',') if item.strip()]))

def parse_ini_bool(value: str) -> bool:
    """è§£æINIå¸ƒå°”é…ç½®"""
    if not value:
        return False
    return value.strip().lower() in ("yes", "true", "1")

def parse_ini_number(value: str, is_int: bool = True) -> Union[int, float, None]:
    """è§£æINIæ•°å­—é…ç½®ï¼ˆæ— é»˜è®¤å€¼ï¼Œè§£æå¤±è´¥è¿”å›Noneï¼‰"""
    if not value:
        return None
    try:
        return int(value.strip()) if is_int else float(value.strip())
    except (ValueError, TypeError):
        return None

# ==============================
# é…ç½®åŠ è½½å’ŒéªŒè¯å‡½æ•°
# ==============================
def load_full_config(config_path: str, cli_args: argparse.Namespace) -> Optional[TaskConfig]:
    """åŠ è½½å®Œæ•´é…ç½®ï¼ˆå®Œå…¨ä»config.iniè¯»å–ï¼Œ[request]èŠ‚é»˜è®¤ç”Ÿæ•ˆï¼‰"""
    print(f"ğŸ“‹ é…ç½®æ–‡ä»¶è·¯å¾„ï¼š{config_path}")

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼")
        return None

    try:
        config = ConfigParser()
        config.optionxform = str
        config.read(config_path, encoding="utf-8")

        # 1. éªŒè¯å¿…å¡«èŠ‚æ˜¯å¦å­˜åœ¨
        missing_sections = [sec for sec in REQUIRED_CONFIG_SECTIONS if not config.has_section(sec)]
        if missing_sections:
            print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…å¡«èŠ‚ï¼š{missing_sections}")
            return None

        # 2. è¯»å–å¹¶éªŒè¯å„èŠ‚é…ç½®
        config_dict = {}

        # [base] èŠ‚
        base_config = {}
        for key in REQUIRED_CONFIG_KEYS['base']:
            value = config.get("base", key, fallback="").strip()
            if not value:
                print(f"âŒ [base] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            base_config[key] = value
        config_dict.update(base_config)

        # [service] èŠ‚ï¼ˆhostå¿…å¡«ï¼Œè¯»å–åè¾“å‡ºï¼‰
        service_config = {}
        for key in REQUIRED_CONFIG_KEYS['service']:
            value = config.get("service", key, fallback="").strip()
            if not value:
                print(f"âŒ [service] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            if key == 'port':
                port = parse_ini_number(value, is_int=True)
                if port is None or not (1 <= port <= 65535):
                    print(f"âŒ [service] èŠ‚ port é…ç½®æ— æ•ˆï¼š{value}ï¼ˆéœ€1-65535ä¹‹é—´çš„æ•´æ•°ï¼‰")
                    return None
                service_config[key] = port
            else:
                service_config[key] = value
        config_dict.update(service_config)

        # è¾“å‡ºå½“å‰ä½¿ç”¨çš„ä¸»æœºåœ°å€
        print(f"ğŸ”Œ å½“å‰æ¥å£è°ƒç”¨ä¸»æœºåœ°å€ï¼š{service_config['host']}ï¼ˆç«¯å£ï¼š{service_config['port']}ï¼‰")
        print(f"âœ… ä¸»æœºé…ç½®åŠ è½½å®Œæˆ")

        # [map] èŠ‚
        map_config = {}
        for key in REQUIRED_CONFIG_KEYS['map']:
            value = config.get("map", key, fallback="").strip()
            if not value:
                print(f"âŒ [map] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            scene_id = parse_ini_number(value, is_int=True)
            if scene_id is None or scene_id <= 0:
                print(f"âŒ [map] èŠ‚ scene_id é…ç½®æ— æ•ˆï¼š{value}ï¼ˆéœ€æ­£æ•´æ•°ï¼‰")
                return None
            map_config[key] = scene_id
        config_dict.update(map_config)

        # [business] èŠ‚
        business_config = {}
        for key in REQUIRED_CONFIG_KEYS['business']:
            value = config.get("business", key, fallback="").strip()
            if not value:
                print(f"âŒ [business] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            if key == 'rule':
                rule = parse_ini_number(value, is_int=True)
                if rule not in VALID_RULES:
                    print(f"âŒ [business] èŠ‚ rule é…ç½®æ— æ•ˆï¼š{value}ï¼ˆä»…æ”¯æŒ{VALID_RULES}ï¼‰")
                    return None
                business_config[key] = rule
            elif key == 'areas':
                areas = parse_ini_list(value)
                if not areas:
                    print(f"âŒ [business] èŠ‚ areas é…ç½®æ— æ•ˆï¼ˆä¸èƒ½ä¸ºç©ºåˆ—è¡¨ï¼‰")
                    return None
                business_config[key] = areas
        # å¯é€‰é…ç½®ï¼šfixed_store
        fixed_store = config.get("business", "fixed_store", fallback="").strip()
        business_config['fixed_store'] = fixed_store
        config_dict.update(business_config)

        # [task] èŠ‚
        task_config = {}
        for key in REQUIRED_CONFIG_KEYS['task']:
            value = config.get("task", key, fallback="").strip()
            if not value:
                print(f"âŒ [task] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            locations = parse_ini_list(value)
            if not locations:
                print(f"âŒ [task] èŠ‚ locations é…ç½®æ— æ•ˆï¼ˆä¸èƒ½ä¸ºç©ºåˆ—è¡¨ï¼‰")
                return None
            task_config[key] = locations
        config_dict.update(task_config)

        # [excel] èŠ‚
        excel_config = {}
        for key in REQUIRED_CONFIG_KEYS['excel']:
            value = config.get("excel", key, fallback="").strip()
            if not value:
                print(f"âŒ [excel] èŠ‚ç¼ºå°‘å¿…å¡«é…ç½®ï¼š{key}")
                return None
            excel_config[key] = value
        # å¯é€‰é…ç½®ï¼šsheet_name
        sheet_name = config.get("excel", "sheet_name", fallback="").strip()
        excel_config['sheet_name'] = sheet_name if sheet_name else None
        config_dict.update(excel_config)

        # [log] èŠ‚ï¼ˆå·²åœ¨æ—¥å¿—åˆå§‹åŒ–æ—¶éªŒè¯è¿‡ï¼‰
        log_config = {}
        log_file = config.get("log", "log_file", fallback="").strip()
        debug_str = config.get("log", "debug", fallback="false").strip()
        log_config['log_file'] = log_file
        log_config['debug'] = parse_ini_bool(debug_str)
        config_dict.update(log_config)

        # [request] èŠ‚ï¼ˆé»˜è®¤ç”Ÿæ•ˆï¼Œä¼˜å…ˆè¯»å–é…ç½®æ–‡ä»¶ï¼Œæ— é…ç½®åˆ™ç”¨é»˜è®¤å€¼ï¼‰
        request_config = {
            'request_timeout': 15.0,
            'retry_count': 0,
            'retry_delay': 1.0
        }
        if config.has_section("request"):
            timeout_str = config.get("request", "timeout", fallback="").strip()
            if timeout_str:
                timeout = parse_ini_number(timeout_str, is_int=False)
                if timeout is not None and timeout > 0:
                    request_config['request_timeout'] = timeout

            retry_count_str = config.get("request", "retry_count", fallback="").strip()
            if retry_count_str:
                retry_count = parse_ini_number(retry_count_str, is_int=True)
                if retry_count is not None and retry_count >= 0:
                    request_config['retry_count'] = retry_count

            retry_delay_str = config.get("request", "retry_delay", fallback="").strip()
            if retry_delay_str:
                retry_delay = parse_ini_number(retry_delay_str, is_int=False)
                if retry_delay is not None and retry_delay >= 0:
                    request_config['retry_delay'] = retry_delay
        config_dict.update(request_config)

        # 3. åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼ˆå¦‚æœæœ‰ï¼‰
        if cli_args.rule is not None:
            if cli_args.rule in VALID_RULES:
                print(f"âš ï¸  å‘½ä»¤è¡Œå‚æ•°è¦†ç›– [business] èŠ‚ ruleï¼š{cli_args.rule}")
                config_dict['rule'] = cli_args.rule
            else:
                print(f"âŒ å‘½ä»¤è¡Œå‚æ•° rule æ— æ•ˆï¼ˆä»…æ”¯æŒ{VALID_RULES}ï¼‰")
                return None

        if cli_args.areas is not None:
            print(f"âš ï¸  å‘½ä»¤è¡Œå‚æ•°è¦†ç›– [business] èŠ‚ areasï¼š{cli_args.areas}")
            config_dict['areas'] = cli_args.areas

        if cli_args.fixed_store is not None:
            print(f"âš ï¸  å‘½ä»¤è¡Œå‚æ•°è¦†ç›– [business] èŠ‚ fixed_storeï¼š{cli_args.fixed_store}")
            config_dict['fixed_store'] = cli_args.fixed_store

        if cli_args.debug:
            print(f"âš ï¸  å‘½ä»¤è¡Œå‚æ•°å¼€å¯ debug æ¨¡å¼")
            config_dict['debug'] = True

        # 4. æœ€ç»ˆéªŒè¯é…ç½®é€»è¾‘
        if config_dict['rule'] == 1 and len(config_dict['areas']) != 1:
            print(f"âŒ è§„åˆ™1è¦æ±‚ areas ä»…å«1ä¸ªåŒºåŸŸï¼Œå½“å‰ï¼š{config_dict['areas']}")
            return None

        if config_dict['rule'] == 2 and len(config_dict['areas']) < 2:
            print(f"âŒ è§„åˆ™2è¦æ±‚ areas è‡³å°‘å«2ä¸ªåŒºåŸŸï¼Œå½“å‰ï¼š{config_dict['areas']}")
            return None

        if config_dict['fixed_store'] and config_dict['fixed_store'] not in config_dict['locations']:
            print(f"âŒ å›ºå®šstore {config_dict['fixed_store']} ä¸åœ¨ locations åˆ—è¡¨ä¸­")
            return None

        # 5. è½¬æ¢ä¸ºé…ç½®å¯¹è±¡
        task_config = TaskConfig(
            # [base]
            account=config_dict['account'],
            password=config_dict['password'],
            token=config_dict['token'],
            # [service]
            host=config_dict['host'],
            port=config_dict['port'],
            # [map]
            scene_id=config_dict['scene_id'],
            # [business]
            rule=config_dict['rule'],
            areas=config_dict['areas'],
            fixed_store=config_dict['fixed_store'],
            # [task]
            locations=config_dict['locations'],
            # [excel]
            xlsx_path=config_dict['xlsx_path'],
            sheet_name=config_dict['sheet_name'],
            # [log]
            debug=config_dict['debug'],
            log_file=config_dict['log_file'],
            # [request]
            request_timeout=config_dict['request_timeout'],
            retry_count=config_dict['retry_count'],
            retry_delay=config_dict['retry_delay']
        )

        # æ—¥å¿—å·²åˆå§‹åŒ–æ—¶è¾“å‡ºé…ç½®ä¿¡æ¯
        if file_logger:
            file_logger.info(f"é…ç½®åŠ è½½æˆåŠŸï¼š{task_config}")
        else:
            print(f"âœ… æ‰€æœ‰é…ç½®åŠ è½½å®Œæˆ")

        return task_config

    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥ï¼š{str(e)}")
        return None

# ==============================
# Excelç›¸å…³å‡½æ•°
# ==============================
@exception_handler(return_value=[])
def load_xlsx_data(xlsx_path: str, sheet_name: Optional[str]) -> List[LocationInfo]:
    """åŠ è½½Excelæ•°æ®ï¼ˆæœªæŒ‡å®šå·¥ä½œè¡¨æ—¶ä½¿ç”¨æœ€æ–°å·¥ä½œè¡¨ï¼ˆæœ€åä¸€ä¸ªï¼‰ï¼‰"""
    console_logger.info(f"ğŸ“Š åŠ è½½Excelæ•°æ®ï¼š{xlsx_path}")
    file_logger.info(f"å¼€å§‹åŠ è½½Excelæ–‡ä»¶ï¼š{xlsx_path}ï¼ŒæŒ‡å®šå·¥ä½œè¡¨ï¼š{sheet_name or 'æ— ï¼ˆå°†ä½¿ç”¨æœ€æ–°å·¥ä½œè¡¨ï¼‰'}")

    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨ï¼š{xlsx_path}")

    # éªŒè¯æ–‡ä»¶æ ¼å¼
    if not xlsx_path.endswith(('.xlsx', '.xlsm')):
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š{xlsx_path}ï¼ˆä»…æ”¯æŒ.xlsx/.xlsmï¼‰")

    try:
        # åªè¯»æ¨¡å¼æ‰“å¼€ï¼Œæå‡æ€§èƒ½
        wb = load_workbook(xlsx_path, read_only=True, data_only=True)
        resource_handles["excel_workbook"] = wb

        # é€‰æ‹©å·¥ä½œè¡¨ï¼šæœªæŒ‡å®šæ—¶ä½¿ç”¨æœ€åä¸€ä¸ªï¼ˆæœ€æ–°ï¼‰å·¥ä½œè¡¨
        if not sheet_name:
            if len(wb.sheetnames) == 0:
                raise ValueError("Excelæ–‡ä»¶ä¸­æ— å¯ç”¨å·¥ä½œè¡¨")
            sheet_name = wb.sheetnames[-1]  # å–æœ€åä¸€ä¸ªå·¥ä½œè¡¨ï¼ˆæœ€æ–°ï¼‰
            console_logger.info(f"ğŸ“‘ æœªæŒ‡å®šå·¥ä½œè¡¨ï¼Œä½¿ç”¨æœ€æ–°å·¥ä½œè¡¨ï¼ˆæœ€åä¸€ä¸ªï¼‰ï¼š{sheet_name}")
            file_logger.info(f"æœªæŒ‡å®šå·¥ä½œè¡¨ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€æ–°å·¥ä½œè¡¨ï¼ˆæœ€åä¸€ä¸ªï¼‰ï¼š{sheet_name}ï¼Œæ‰€æœ‰å·¥ä½œè¡¨ï¼š{wb.sheetnames}")
        
        if sheet_name not in wb.sheetnames:
            raise ValueError(f"å·¥ä½œè¡¨ '{sheet_name}' ä¸å­˜åœ¨ï¼Œå¯ç”¨å·¥ä½œè¡¨ï¼š{wb.sheetnames}")
        
        ws = wb[sheet_name]
        file_logger.info(f"æˆåŠŸæ‰“å¼€å·¥ä½œè¡¨ï¼š{sheet_name}ï¼ˆæ€»è¡Œæ•°ï¼š{ws.max_row}ï¼‰")

        # è§£æè¡¨å¤´
        headers = []
        for cell in ws[1]:
            header_value = cell.value.strip() if cell.value and isinstance(cell.value, str) else str(cell.value) if cell.value else None
            headers.append(header_value)
        
        # éªŒè¯å¿…è¦åˆ—
        missing_cols = REQUIRED_EXCEL_COLUMNS - set(headers)
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}ï¼ˆéœ€åŒ…å« {REQUIRED_EXCEL_COLUMNS}ï¼‰")
        
        id_col_idx = headers.index('id')
        alias_col_idx = headers.index('alias_kept')
        file_logger.info(f"è¡¨å¤´è§£ææˆåŠŸï¼šidåˆ—ç´¢å¼•={id_col_idx}ï¼Œalias_keptåˆ—ç´¢å¼•={alias_col_idx}")

        # è§£ææ•°æ®ï¼ˆåˆ†æ‰¹è¯»å–ï¼Œæå‡å¤§æ–‡ä»¶æ€§èƒ½ï¼‰
        location_list = []
        batch_size = 1000
        batch_count = 0
        
        for row_num, row in enumerate(ws.iter_rows(min_row=2, values_only=True), start=2):
            # è·³è¿‡ç©ºè¡Œ
            if all(cell is None for cell in row):
                continue
            
            # è§£ælocation_id
            location_id = row[id_col_idx]
            if location_id is None:
                file_logger.warning(f"ç¬¬ {row_num} è¡Œï¼šidä¸ºç©ºï¼Œè·³è¿‡")
                task_stats.skipped += 1
                continue
            
            location_id = str(location_id).strip()
            if not location_id:
                file_logger.warning(f"ç¬¬ {row_num} è¡Œï¼šidä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè·³è¿‡")
                task_stats.skipped += 1
                continue

            # è§£æalias_kept
            alias_kept = row[alias_col_idx] or ""
            alias_kept = str(alias_kept).strip().replace(" - ", "-")
            if not alias_kept:
                file_logger.warning(f"ç¬¬ {row_num} è¡Œï¼šalias_keptä¸ºç©ºï¼Œè·³è¿‡ï¼ˆidï¼š{location_id}ï¼‰")
                task_stats.skipped += 1
                continue

            # è§£æåŒºåŸŸå’Œç¼–å·ï¼ˆæ”¯æŒå­—æ¯æ•°å­—æ··åˆåŒºåŸŸï¼Œå¦‚hoist_Lã€hoist_Rï¼‰
            parts = alias_kept.rsplit('-', 1)
            if len(parts) == 2 and parts[1].strip().isdigit():
                area = parts[0].strip()
                number = int(parts[1].strip())
            else:
                # å¤„ç†æ— ç¼–å·çš„åŒºåŸŸï¼ˆå¦‚hoist_Lã€hoist_Rï¼‰
                area = alias_kept.strip()
                number = 0  # ç”¨0è¡¨ç¤ºæ— ç¼–å·
            
            if not area:
                file_logger.warning(f"ç¬¬ {row_num} è¡Œï¼šåŒºåŸŸä¸ºç©ºï¼ˆ{alias_kept}ï¼‰ï¼Œè·³è¿‡ï¼ˆidï¼š{location_id}ï¼‰")
                task_stats.skipped += 1
                continue

            # æ·»åŠ åˆ°åˆ—è¡¨
            full_area = alias_kept.strip()  # ç›´æ¥ä½¿ç”¨åŸå§‹alias_keptä½œä¸ºå®Œæ•´åŒºåŸŸæ ‡è¯†
            location_info = LocationInfo(
                location_id=location_id,
                area=area,
                number=number,
                full_area=full_area
            )
            location_list.append(location_info)

            # æ‰¹é‡æ—¥å¿—
            batch_count += 1
            if batch_count % batch_size == 0:
                file_logger.info(f"å·²è§£æ {len(location_list)} æ¡æ•°æ®ï¼ˆå½“å‰è¡Œï¼š{row_num}ï¼‰")

        # ç»Ÿè®¡ä¿¡æ¯
        parsed_areas = list({item.area for item in location_list})
        console_logger.info(f"âœ… ExcelåŠ è½½å®Œæˆï¼š")
        console_logger.info(f"  - æœ‰æ•ˆæ•°æ®ï¼š{len(location_list)} æ¡")
        console_logger.info(f"  - æ€»è¡Œæ•°ï¼š{ws.max_row - 1} è¡Œ")
        console_logger.info(f"  - è·³è¿‡è¡Œæ•°ï¼š{task_stats.skipped} è¡Œ")
        console_logger.info(f"  - è§£æåŒºåŸŸï¼š{len(parsed_areas)} ä¸ªï¼ˆ{sorted(parsed_areas)}ï¼‰")
        
        file_logger.info(f"ExcelåŠ è½½å®Œæˆï¼šæœ‰æ•ˆæ•°æ®{len(location_list)}æ¡ï¼Œæ€»è¡Œæ•°{ws.max_row - 1}è¡Œï¼Œè·³è¿‡{task_stats.skipped}è¡Œï¼Œè§£æåŒºåŸŸ{len(parsed_areas)}ä¸ª")
        return location_list

    except Exception as e:
        if file_logger:
            file_logger.error(f"ExcelåŠ è½½å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise

# ==============================
# åŒºåŸŸå¤„ç†ç›¸å…³å‡½æ•°
# ==============================
@exception_handler(return_value=(None, None))
def group_and_validate_areas(
    locations: List[LocationInfo], 
    selected_areas: List[str]
) -> Tuple[Optional[Dict[str, List[LocationInfo]]], Optional[List[str]]]:
    """åŒºåŸŸåˆ†ç»„ä¸éªŒè¯ï¼ˆæ”¯æŒå­—æ¯æ•°å­—æ··åˆåŒºåŸŸï¼‰"""
    console_logger.info(f"\nğŸ” åŒºåŸŸåˆ†ç»„ä¸éªŒè¯...")
    file_logger.info(f"å¼€å§‹åŒºåŸŸéªŒè¯ï¼šé…ç½®åŒºåŸŸ={sorted(selected_areas)}ï¼ˆä»…æ¥è‡ª[business]èŠ‚ï¼‰")

    # æŒ‰åŒºåŸŸåˆ†ç»„ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼Œæ”¯æŒç²¾ç¡®åŒ¹é…ï¼‰
    grouped = {}
    for loc in locations:
        area_key = loc.area
        if area_key not in grouped:
            grouped[area_key] = []
        grouped[area_key].append(loc)
    
    # æ’åºå¹¶è¿‡æ»¤ç©ºç»„
    grouped = {
        area: sorted(locs, key=lambda x: (x.number, x.full_area)) 
        for area, locs in grouped.items() 
        if area and locs
    }

    # éªŒè¯é€»è¾‘
    available_areas = set(grouped.keys())
    selected_areas_set = set(selected_areas)
    matched_areas = selected_areas_set & available_areas
    unmatched_areas = selected_areas_set - available_areas
    valid_areas = sorted([area for area in matched_areas if len(grouped[area]) > 0])
    empty_areas = sorted([area for area in matched_areas if len(grouped[area]) == 0])

    # è¯¦ç»†æ—¥å¿—
    file_logger.info(f"åŒºåŸŸéªŒè¯è¯¦æƒ…ï¼š")
    file_logger.info(f"  - é…ç½®åŒºåŸŸï¼ˆæ¥è‡ª[business]èŠ‚ï¼‰ï¼š{sorted(selected_areas)}")
    file_logger.info(f"  - å¯ç”¨åŒºåŸŸï¼š{sorted(available_areas)}")
    file_logger.info(f"  - åŒ¹é…åŒºåŸŸï¼š{sorted(matched_areas)}")
    file_logger.info(f"  - ä¸åŒ¹é…åŒºåŸŸï¼š{sorted(unmatched_areas) if unmatched_areas else 'æ— '}")
    file_logger.info(f"  - ç©ºåŒºåŸŸï¼ˆæ— ä»»åŠ¡ï¼‰ï¼š{empty_areas if empty_areas else 'æ— '}")
    file_logger.info(f"  - æœ‰æ•ˆåŒºåŸŸï¼š{valid_areas}")

    # é”™è¯¯å¤„ç†
    if unmatched_areas:
        raise ValueError(f"ä»¥ä¸‹åŒºåŸŸåœ¨Excelä¸­ä¸å­˜åœ¨ï¼š{sorted(unmatched_areas)}")
    if empty_areas:
        raise ValueError(f"ä»¥ä¸‹åŒºåŸŸæ— ä»»åŠ¡æ•°æ®ï¼š{empty_areas}")
    if not valid_areas:
        raise ValueError("æ— æœ‰æ•ˆåŒºåŸŸï¼ˆåŒ¹é…åŒºåŸŸå‡æ— ä»»åŠ¡ï¼‰")

    # ç»Ÿè®¡ä»»åŠ¡æ•°
    total_task_count = sum(len(locs) for locs in grouped.values() if locs[0].area in valid_areas)
    task_stats.total_task_count = total_task_count
    task_stats.valid_areas = valid_areas

    # æ§åˆ¶å°è¾“å‡º
    console_logger.info(f"âœ… åŒºåŸŸéªŒè¯é€šè¿‡ï¼")
    console_logger.info(f"  - æœ‰æ•ˆåŒºåŸŸï¼š{len(valid_areas)} ä¸ªï¼ˆ{valid_areas}ï¼‰")
    console_logger.info(f"  - å¾…æ‰§è¡Œä»»åŠ¡ï¼š{total_task_count} ä¸ª")
    file_logger.info(f"åŒºåŸŸéªŒè¯é€šè¿‡ï¼šæœ‰æ•ˆåŒºåŸŸ{len(valid_areas)}ä¸ªï¼Œå¾…æ‰§è¡Œä»»åŠ¡{total_task_count}ä¸ª")

    return grouped, valid_areas

# ==============================
# HTTPè¯·æ±‚ç›¸å…³å‡½æ•°
# ==============================
def init_http_session(config: TaskConfig) -> requests.Session:
    """åˆå§‹åŒ–HTTPä¼šè¯ï¼ˆä½¿ç”¨[request]èŠ‚é…ç½®ï¼‰"""
    session = requests.Session()
    
    # é…ç½®é‡è¯•ç­–ç•¥ï¼ˆä½¿ç”¨[request]èŠ‚çš„retry_countå’Œretry_delayï¼‰
    retry_strategy = Retry(
        total=config.retry_count,
        backoff_factor=config.retry_delay,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["PUT"]
    )
    
    adapter = HTTPAdapter(
        max_retries=retry_strategy,
        pool_connections=10,
        pool_maxsize=10
    )
    
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    resource_handles["http_session"] = session
    file_logger.info(f"HTTPä¼šè¯åˆå§‹åŒ–å®Œæˆï¼šè¶…æ—¶={config.request_timeout}sï¼Œé‡è¯•={config.retry_count}æ¬¡ï¼Œå»¶è¿Ÿ={config.retry_delay}s")
    return session

def check_continuous_failures() -> bool:
    """æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°æ˜¯å¦è¾¾åˆ°é˜ˆå€¼ï¼Œè¾¾åˆ°åˆ™è¿”å›Trueï¼ˆéœ€è¦åœæ­¢ç¨‹åºï¼‰"""
    if task_stats.continuous_failures >= MAX_CONTINUOUS_FAILURES:
        error_msg = f"âš ï¸  è¿ç»­{MAX_CONTINUOUS_FAILURES}æ¬¡æ¥å£è°ƒç”¨å¤±è´¥ï¼Œç¨‹åºå·²åœæ­¢ï¼è¯·æ£€æŸ¥åº“ä½IDæœ‰æ•ˆæ€§ã€æ¥å£é…ç½®æˆ–æœåŠ¡çŠ¶æ€ã€‚"
        console_logger.error(error_msg)
        file_logger.error(error_msg)
        # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Šå¹¶æ¸…ç†èµ„æº
        task_stats.end_time = datetime.now()
        print_final_report()
        cleanup_resources()
        sys.exit(3)  # è¿ç»­å¤±è´¥é€€å‡ºç 
    return False

@exception_handler(return_value=False)
def send_task(
    session: requests.Session,
    location_id: str,
    store_location_id: str,
    config: TaskConfig
) -> bool:
    """å‘é€æ¥å£è¯·æ±‚ï¼ˆæ”¯æŒè¿”å›æ ¡éªŒï¼šerror_id == 50421021 æ‰è§†ä¸ºæˆåŠŸï¼‰"""
    url = f"http://{config.host}:{config.port}/dispatch_server/dispatch/start/location_call/task/"
    headers = {
        "Authorization": f"Bearer {config.token}",
        "Content-Type": "application/json"
    }
    payload = {
        "location_id": location_id,
        "store_location_id": store_location_id,
        "scene_id": config.scene_id
    }

    # è°ƒè¯•æ—¥å¿—
    if config.debug and file_logger:
        file_logger.debug(f"å‘é€è¯·æ±‚ï¼š")
        file_logger.debug(f"  URLï¼š{url}")
        file_logger.debug(f"  Headersï¼š{headers}")
        file_logger.debug(f"  Payloadï¼š{payload}")
        file_logger.debug(f"  è¶…æ—¶ï¼š{config.request_timeout}sï¼Œé‡è¯•ï¼š{config.retry_count}æ¬¡")

    try:
        response = session.put(
            url,
            json=payload,
            headers=headers,
            timeout=config.request_timeout
        )
        response.raise_for_status()

        # è§£æå“åº”JSON
        try:
            resp_data = response.json()
        except json.JSONDecodeError as e:
            error_msg = f"å“åº”æ ¼å¼é”™è¯¯ï¼ˆéJSONï¼‰ï¼š{response.text[:500]}"
            file_logger.error(f"è¯·æ±‚å¤±è´¥ï¼š{error_msg} | location_id={location_id}ï¼Œstore={store_location_id}")
            # æ›´æ–°è¿ç»­å¤±è´¥è®¡æ•°
            task_stats.continuous_failures += 1
            console_logger.error(f"  âŒ æ‰§è¡Œå¤±è´¥ï¼š{error_msg}")
            console_logger.warning(f"  âš ï¸  è¿ç»­å¤±è´¥æ¬¡æ•°ï¼š{task_stats.continuous_failures}/{MAX_CONTINUOUS_FAILURES}")
            return False

        # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºå®Œæ•´å“åº”
        if config.debug and file_logger:
            file_logger.debug(f"å“åº”æ•°æ®ï¼š{json.dumps(resp_data, ensure_ascii=False, indent=2)}")

        # æ ¡éªŒè¿”å›ç»“æœ
        success = resp_data.get("success", False)
        error_id = resp_data.get("msg", {}).get("detail", {}).get("error_id")
        
        # å¤„ç†é”™è¯¯ä¿¡æ¯ï¼ˆä¸ºç©ºæ—¶æ˜¾ç¤ºé»˜è®¤å€¼ï¼‰
        error_info = resp_data.get("msg", {}).get("detail", {}).get("info", "")
        # å»é™¤å‰åç©ºæ ¼ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºç©º
        if not error_info or str(error_info).strip() == "":
            error_info = DEFAULT_ERROR_INFO
        else:
            error_info = str(error_info).strip()

        # æ ¡éªŒé€»è¾‘ï¼šä»…å½“successä¸ºTrue æˆ– (successä¸ºFalseä½†error_id == TARGET_ERROR_ID) æ—¶è§†ä¸ºæˆåŠŸ
        if success or (error_id is not None and error_id == TARGET_ERROR_ID):
            # æˆåŠŸæ—¥å¿—ä¼˜åŒ–ï¼šä¸æ˜¾ç¤ºNoneçš„error_id
            success_log_parts = [
                f"è¯·æ±‚æˆåŠŸï¼šlocation_id={location_id}ï¼Œstore={store_location_id}",
                f"çŠ¶æ€ç ={response.status_code}",
                f"success={success}"
            ]
            # åªæœ‰error_idå­˜åœ¨æ—¶æ‰æ·»åŠ åˆ°æ—¥å¿—
            if error_id is not None:
                success_log_parts.append(f"error_id={error_id}")
            file_logger.info(" | ".join(success_log_parts))
            
            # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
            task_stats.continuous_failures = 0
            return True
        else:
            # å¤±è´¥å¤„ç†ï¼šç¡®ä¿infoæœ‰é»˜è®¤å€¼ï¼Œerror_idæ˜¾ç¤ºä¸º"æ— "å¦‚æœæ˜¯None
            display_error_id = error_id if error_id is not None else "æ— "
            error_detail = f"{error_info}ï¼ˆerror_idï¼š{display_error_id}ï¼‰"
            
            # å¤±è´¥æ—¥å¿—ä¼˜åŒ–ï¼šæ˜ç¡®æ˜¾ç¤ºç©ºå€¼æƒ…å†µ
            file_logger.error(
                f"è¯·æ±‚å¤±è´¥ï¼šlocation_id={location_id}ï¼Œstore={store_location_id} | "
                f"çŠ¶æ€ç ={response.status_code}ï¼Œsuccess={success}ï¼Œ"
                f"error_id={display_error_id}ï¼Œinfo={error_info}"
            )
            
            # æ›´æ–°è¿ç»­å¤±è´¥è®¡æ•°
            task_stats.continuous_failures += 1
            console_logger.error(f"  âŒ æ‰§è¡Œå¤±è´¥ï¼š{error_detail}")
            console_logger.warning(f"  âš ï¸  è¿ç»­å¤±è´¥æ¬¡æ•°ï¼š{task_stats.continuous_failures}/{MAX_CONTINUOUS_FAILURES}")
            return False

    except requests.exceptions.RequestException as e:
        error_details = []
        error_details.append(f"é”™è¯¯ç±»å‹ï¼š{type(e).__name__}")
        error_details.append(f"é”™è¯¯ä¿¡æ¯ï¼š{str(e)}")
        
        if hasattr(e, 'response') and e.response is not None:
            error_details.append(f"çŠ¶æ€ç ï¼š{e.response.status_code}")
            error_details.append(f"å“åº”å†…å®¹ï¼š{e.response.text[:500]}")  # é™åˆ¶é•¿åº¦
        
        error_msg = " | ".join(error_details)
        file_logger.error(
            f"è¯·æ±‚å¤±è´¥ï¼šlocation_id={location_id}ï¼Œstore={store_location_id} | {error_msg}",
            exc_info=config.debug  # è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºå®Œæ•´å †æ ˆ
        )
        # æ›´æ–°è¿ç»­å¤±è´¥è®¡æ•°
        task_stats.continuous_failures += 1
        console_logger.error(f"  âŒ æ‰§è¡Œå¤±è´¥ï¼šç½‘ç»œè¯·æ±‚å¼‚å¸¸ - {str(e)}")
        console_logger.warning(f"  âš ï¸  è¿ç»­å¤±è´¥æ¬¡æ•°ï¼š{task_stats.continuous_failures}/{MAX_CONTINUOUS_FAILURES}")
        return False

# ==============================
# ä»»åŠ¡æ‰§è¡Œç›¸å…³å‡½æ•°
# ==============================
def run_rule1(
    grouped_areas: Dict[str, List[LocationInfo]],
    valid_areas: List[str],
    config: TaskConfig
):
    """è§„åˆ™1ï¼šå•ä¸ªåŒºåŸŸé¡ºåºæ‰§è¡Œï¼ˆåŒ…å«è¿ç»­å¤±è´¥æ£€æŸ¥ï¼‰"""
    global is_running
    is_running = True
    target_area = valid_areas[0]
    area_locations = grouped_areas[target_area]
    session = init_http_session(config)

    console_logger.info(f"\nğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆè§„åˆ™1ï¼šåŒºåŸŸ{target_area}é¡ºåºè°ƒç”¨ï¼‰")
    file_logger.info(
        f"å¼€å§‹æ‰§è¡Œè§„åˆ™1ï¼šç›®æ ‡åŒºåŸŸ={target_area}ï¼ˆæ¥è‡ª[business]èŠ‚areasï¼‰ï¼Œä»»åŠ¡æ•°={len(area_locations)}ï¼Œ"
        f"storeæ¨¡å¼={'å›ºå®šï¼š' + config.fixed_store if config.fixed_store else 'éšæœº'}ï¼Œ"
        f"è¯·æ±‚é…ç½®ï¼šè¶…æ—¶={config.request_timeout}sï¼Œé‡è¯•={config.retry_count}æ¬¡ï¼Œ"
        f"æˆåŠŸæ¡ä»¶ï¼šsuccess=true æˆ– error_id={TARGET_ERROR_ID}"
    )

    try:
        for idx, loc in enumerate(area_locations, start=1):
            if not is_running:
                break

            # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°ï¼Œè¾¾åˆ°é˜ˆå€¼åˆ™åœæ­¢
            if check_continuous_failures():
                return

            # é€‰æ‹©store
            selected_store = config.fixed_store if config.fixed_store else random.choice(config.locations)
            
            # æ§åˆ¶å°è¿›åº¦æ˜¾ç¤º
            console_logger.info(f"\n[{idx}/{len(area_locations)}] åŒºåŸŸï¼š{loc.full_area} | IDï¼š{loc.location_id}")
            
            # å‘é€ä»»åŠ¡
            success = send_task(session, loc.location_id, selected_store, config)

            # æ›´æ–°ç»Ÿè®¡
            if success:
                task_stats.success += 1
                console_logger.info(f"  âœ… æ‰§è¡ŒæˆåŠŸ | ç›®æ ‡storeï¼š{selected_store}")
            else:
                task_stats.fail += 1
            task_stats.total += 1

            # ä»»åŠ¡é—´éš”
            if idx < len(area_locations):
                time.sleep(0.5)

    except Exception as e:
        console_logger.error(f"\nâŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
        if file_logger:
            file_logger.error(f"è§„åˆ™1æ‰§è¡Œå¼‚å¸¸", exc_info=True)
    finally:
        is_running = False

    # æ‰§è¡Œç»“æœ
    if idx == len(area_locations) and is_running:
        console_logger.info(f"\nğŸ‰ åŒºåŸŸ{target_area}æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")
    else:
        console_logger.info(f"\nâš ï¸  ä»»åŠ¡æ‰§è¡Œè¢«ä¸­æ–­ï¼ˆå·²æ‰§è¡Œ{idx-1}/{len(area_locations)}ä¸ªä»»åŠ¡ï¼‰")
    
    if file_logger:
        file_logger.info(
            f"è§„åˆ™1æ‰§è¡Œç»“æŸï¼šæ€»æ‰§è¡Œ{task_stats.total}ä¸ªï¼ŒæˆåŠŸ{task_stats.success}ä¸ªï¼Œ"
            f"å¤±è´¥{task_stats.fail}ä¸ªï¼Œä¸­æ–­çŠ¶æ€={not is_running}ï¼Œæœ€ç»ˆè¿ç»­å¤±è´¥æ¬¡æ•°={task_stats.continuous_failures}"
        )

def run_rule2(
    grouped_areas: Dict[str, List[LocationInfo]],
    valid_areas: List[str],
    config: TaskConfig
):
    """è§„åˆ™2ï¼šå¤šä¸ªåŒºåŸŸéšæœºæ‰§è¡Œï¼ˆåŒ…å«è¿ç»­å¤±è´¥æ£€æŸ¥ï¼‰"""
    global is_running
    is_running = True
    session = init_http_session(config)

    # åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¤åˆ¶åˆ—è¡¨é¿å…ä¿®æ”¹åŸæ•°æ®ï¼‰
    area_tasks = {area: grouped_areas[area].copy() for area in valid_areas}
    remaining_areas = [area for area in valid_areas if area_tasks[area]]

    console_logger.info(f"\nğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆè§„åˆ™2ï¼šéšæœºè°ƒç”¨ï¼‰")
    if file_logger:
        file_logger.info(
            f"å¼€å§‹æ‰§è¡Œè§„åˆ™2ï¼šæœ‰æ•ˆåŒºåŸŸ={sorted(valid_areas)}ï¼ˆæ¥è‡ª[business]èŠ‚areasï¼‰ï¼ŒåŒºåŸŸä»»åŠ¡æ•°={ {k:len(v) for k,v in area_tasks.items()} }ï¼Œ"
            f"storeæ¨¡å¼={'å›ºå®šï¼š' + config.fixed_store if config.fixed_store else 'éšæœº'}ï¼Œ"
            f"è¯·æ±‚é…ç½®ï¼šè¶…æ—¶={config.request_timeout}sï¼Œé‡è¯•={config.retry_count}æ¬¡ï¼Œ"
            f"æˆåŠŸæ¡ä»¶ï¼šsuccess=true æˆ– error_id={TARGET_ERROR_ID}"
        )

    try:
        while remaining_areas and is_running:
            # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°ï¼Œè¾¾åˆ°é˜ˆå€¼åˆ™åœæ­¢
            if check_continuous_failures():
                return

            # éšæœºé€‰æ‹©åŒºåŸŸ
            current_area = random.choice(remaining_areas)
            current_loc = area_tasks[current_area].pop(0)
            
            # é€‰æ‹©store
            selected_store = config.fixed_store if config.fixed_store else random.choice(config.locations)
            
            # ä»»åŠ¡åºå·
            task_seq = task_stats.total + 1
            
            # æ§åˆ¶å°è¿›åº¦æ˜¾ç¤º
            console_logger.info(f"\n[{task_seq}/{task_stats.total_task_count}] åŒºåŸŸï¼š{current_loc.full_area} | IDï¼š{current_loc.location_id}")
            
            # å‘é€ä»»åŠ¡
            success = send_task(session, current_loc.location_id, selected_store, config)

            # æ›´æ–°ç»Ÿè®¡
            if success:
                task_stats.success += 1
                console_logger.info(f"  âœ… æ‰§è¡ŒæˆåŠŸ | ç›®æ ‡storeï¼š{selected_store}")
            else:
                task_stats.fail += 1
            task_stats.total += 1

            # æ›´æ–°å‰©ä½™åŒºåŸŸåˆ—è¡¨
            remaining_areas = [area for area in valid_areas if area_tasks[area]]
            
            # ä»»åŠ¡é—´éš”
            if remaining_areas:
                time.sleep(0.5)

    except Exception as e:
        console_logger.error(f"\nâŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
        if file_logger:
            file_logger.error(f"è§„åˆ™2æ‰§è¡Œå¼‚å¸¸", exc_info=True)
    finally:
        is_running = False

    # æ‰§è¡Œç»“æœ
    if not remaining_areas and is_running:
        console_logger.info(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")
    else:
        remaining_task_count = sum(len(tasks) for tasks in area_tasks.values())
        console_logger.info(f"\nâš ï¸  ä»»åŠ¡æ‰§è¡Œè¢«ä¸­æ–­ï¼ˆå·²æ‰§è¡Œ{task_stats.total}ä¸ªï¼Œå‰©ä½™{remaining_task_count}ä¸ªï¼‰")
    
    if file_logger:
        file_logger.info(
            f"è§„åˆ™2æ‰§è¡Œç»“æŸï¼šæ€»æ‰§è¡Œ{task_stats.total}ä¸ªï¼ŒæˆåŠŸ{task_stats.success}ä¸ªï¼Œ"
            f"å¤±è´¥{task_stats.fail}ä¸ªï¼Œå‰©ä½™ä»»åŠ¡æ•°={sum(len(tasks) for tasks in area_tasks.values())}ï¼Œ"
            f"æœ€ç»ˆè¿ç»­å¤±è´¥æ¬¡æ•°={task_stats.continuous_failures}"
        )

# ==============================
# æŠ¥å‘Šå’Œæ¸…ç†å‡½æ•°
# ==============================
def print_final_report():
    """è¾“å‡ºæœ€ç»ˆæŠ¥å‘Šï¼ˆåŒ…å«è¿ç»­å¤±è´¥æ¬¡æ•°ï¼‰"""
    if not task_stats.start_time:
        return

    # è®¡ç®—æ‰§è¡Œæ—¶é•¿
    end_time = task_stats.end_time or datetime.now()
    duration = (end_time - task_stats.start_time).total_seconds()
    duration_str = str(timedelta(seconds=duration)).split('.')[0]  # æ ¼å¼åŒ–æ—¶é•¿

    # è®¡ç®—æˆåŠŸç‡
    success_rate = (task_stats.success / task_stats.total * 100) if task_stats.total > 0 else 0.0

    # æ§åˆ¶å°ç®€æ´æŠ¥å‘Š
    console_logger.info(f"\n" + "="*60)
    console_logger.info(f"ğŸ¯ ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š")
    console_logger.info(f"="*60)
    console_logger.info(f"å¯åŠ¨æ—¶é—´ï¼š{task_stats.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    console_logger.info(f"ç»“æŸæ—¶é—´ï¼š{end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    console_logger.info(f"æ‰§è¡Œæ—¶é•¿ï¼š{duration_str}")
    console_logger.info(f"æ¥å£ä¸»æœºï¼š{global_config.host}:{global_config.port}")
    console_logger.info(f"Excelå·¥ä½œè¡¨ï¼š{global_config.sheet_name or 'æœ€æ–°å·¥ä½œè¡¨ï¼ˆæœ€åä¸€ä¸ªï¼‰'}")
    console_logger.info(f"æ‰§è¡Œè§„åˆ™ï¼š{global_config.rule}")
    console_logger.info(f"æ‰§è¡ŒåŒºåŸŸï¼ˆæ¥è‡ª[business]èŠ‚ï¼‰ï¼š{sorted(task_stats.valid_areas)}")
    console_logger.info(f"Storeæ¨¡å¼ï¼š{'å›ºå®šï¼š' + global_config.fixed_store if global_config.fixed_store else 'éšæœº'}")
    console_logger.info(f"è¯·æ±‚é…ç½®ï¼šè¶…æ—¶={global_config.request_timeout}sï¼Œé‡è¯•={global_config.retry_count}æ¬¡")
    console_logger.info(f"æˆåŠŸæ¡ä»¶ï¼šsuccess=true æˆ– error_id={TARGET_ERROR_ID}")
    console_logger.info(f"="*60)
    console_logger.info(f"æ€»å¾…æ‰§è¡Œä»»åŠ¡ï¼š{task_stats.total_task_count} ä¸ª")
    console_logger.info(f"å·²æ‰§è¡Œä»»åŠ¡ï¼š{task_stats.total} ä¸ª")
    console_logger.info(f"æˆåŠŸä»»åŠ¡ï¼š{task_stats.success} ä¸ªï¼ˆ{success_rate:.1f}%ï¼‰")
    console_logger.info(f"å¤±è´¥ä»»åŠ¡ï¼š{task_stats.fail} ä¸ªï¼ˆ{100-success_rate:.1f}%ï¼‰")
    console_logger.info(f"è·³è¿‡ä»»åŠ¡ï¼š{task_stats.skipped} ä¸ª")
    console_logger.info(f"æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°ï¼š{task_stats.continuous_failures}/{MAX_CONTINUOUS_FAILURES}")
    console_logger.info(f"="*60)

    # æ–‡ä»¶è¯¦ç»†æŠ¥å‘Š
    if file_logger:
        file_logger.info(f"\n" + "="*80)
        file_logger.info(f"ä»»åŠ¡æ‰§è¡Œæœ€ç»ˆæŠ¥å‘Š")
        file_logger.info(f"="*80)
        file_logger.info(f"å¯åŠ¨æ—¶é—´ï¼š{task_stats.start_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
        file_logger.info(f"ç»“æŸæ—¶é—´ï¼š{end_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
        file_logger.info(f"æ‰§è¡Œæ—¶é•¿ï¼š{duration:.3f} ç§’")
        file_logger.info(f"æ¥å£ä¸»æœºï¼š{global_config.host}:{global_config.port}")
        file_logger.info(f"Excelæ–‡ä»¶ï¼š{global_config.xlsx_path}")
        file_logger.info(f"Excelå·¥ä½œè¡¨ï¼š{global_config.sheet_name or 'æœ€æ–°å·¥ä½œè¡¨ï¼ˆæœ€åä¸€ä¸ªï¼‰'}")
        file_logger.info(f"æ‰§è¡Œè§„åˆ™ï¼š{global_config.rule}")
        file_logger.info(f"æ‰§è¡ŒåŒºåŸŸï¼ˆæ¥è‡ª[business]èŠ‚areasï¼‰ï¼š{sorted(task_stats.valid_areas)}")
        file_logger.info(f"Storeæ¨¡å¼ï¼š{'å›ºå®šï¼š' + global_config.fixed_store if global_config.fixed_store else 'éšæœº'}")
        file_logger.info(f"åœºæ™¯IDï¼š{global_config.scene_id}")
        file_logger.info(f"è¯·æ±‚é…ç½®ï¼šè¶…æ—¶={global_config.request_timeout}sï¼Œé‡è¯•={global_config.retry_count}æ¬¡ï¼Œå»¶è¿Ÿ={global_config.retry_delay}s")
        file_logger.info(f"æˆåŠŸæ¡ä»¶ï¼šsuccess=true æˆ– error_id={TARGET_ERROR_ID}")
        file_logger.info(f"æœ€å¤§è¿ç»­å¤±è´¥é˜ˆå€¼ï¼š{MAX_CONTINUOUS_FAILURES}æ¬¡")
        file_logger.info(f"é»˜è®¤é”™è¯¯ä¿¡æ¯ï¼š{DEFAULT_ERROR_INFO}")
        file_logger.info(f"="*80)
        file_logger.info(f"æ€»å¾…æ‰§è¡Œä»»åŠ¡æ•°ï¼š{task_stats.total_task_count} ä¸ª")
        file_logger.info(f"å·²æ‰§è¡Œä»»åŠ¡æ•°ï¼š{task_stats.total} ä¸ª")
        file_logger.info(f"æˆåŠŸä»»åŠ¡æ•°ï¼š{task_stats.success} ä¸ªï¼ˆ{success_rate:.2f}%ï¼‰")
        file_logger.info(f"å¤±è´¥ä»»åŠ¡æ•°ï¼š{task_stats.fail} ä¸ªï¼ˆ{100-success_rate:.2f}%ï¼‰")
        file_logger.info(f"è·³è¿‡ä»»åŠ¡æ•°ï¼š{task_stats.skipped} ä¸ª")
        file_logger.info(f"æœ€ç»ˆè¿ç»­å¤±è´¥æ¬¡æ•°ï¼š{task_stats.continuous_failures}")
        file_logger.info(f"="*80)

def cleanup_resources():
    """æ¸…ç†èµ„æºï¼ˆå…³é—­Excelå·¥ä½œç°¿ã€HTTPä¼šè¯ï¼‰"""
    global resource_handles
    if file_logger:
        file_logger.info("å¼€å§‹æ¸…ç†èµ„æº...")

    # å…³é—­Excelå·¥ä½œç°¿
    if resource_handles.get("excel_workbook"):
        try:
            resource_handles["excel_workbook"].close()
            if file_logger:
                file_logger.info("Excelå·¥ä½œç°¿å·²å…³é—­")
        except Exception as e:
            if file_logger:
                file_logger.error(f"å…³é—­Excelå·¥ä½œç°¿å¤±è´¥ï¼š{str(e)}")

    # å…³é—­HTTPä¼šè¯
    if resource_handles.get("http_session"):
        try:
            resource_handles["http_session"].close()
            if file_logger:
                file_logger.info("HTTPä¼šè¯å·²å…³é—­")
        except Exception as e:
            if file_logger:
                file_logger.error(f"å…³é—­HTTPä¼šè¯å¤±è´¥ï¼š{str(e)}")

    # é‡ç½®èµ„æºå¥æŸ„
    resource_handles = {"excel_workbook": None, "http_session": None}
    if file_logger:
        file_logger.info("èµ„æºæ¸…ç†å®Œæˆ")

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å‡½æ•°ï¼ˆå¤„ç†Ctrl+Cä¸­æ–­ï¼‰"""
    global is_running
    if not is_running:
        console_logger.info("\nâš ï¸  ç¨‹åºæ­£åœ¨é€€å‡º...")
        cleanup_resources()
        sys.exit(1)
    
    console_logger.info("\nâš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢ä»»åŠ¡...ï¼ˆå†æ¬¡æŒ‰ä¸‹Ctrl+Cå°†å¼ºåˆ¶é€€å‡ºï¼‰")
    is_running = False

# ==============================
# ä¸»å‡½æ•°
# ==============================
def main():
    global global_config, task_stats

    # æ³¨å†Œä¿¡å·å¤„ç†ï¼ˆCtrl+Cï¼‰
    signal.signal(signal.SIGINT, signal_handler)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="åŒºåŸŸå–è´§åˆ°æå‡æœºä»»åŠ¡è°ƒç”¨å·¥å…·")
    parser.add_argument("--config", type=str, default="./config.ini", help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼š./config.iniï¼‰")
    parser.add_argument("--rule", type=int, choices=VALID_RULES, help=f"æ‰§è¡Œè§„åˆ™ï¼ˆ1=å•ä¸ªåŒºåŸŸé¡ºåºï¼›2=å¤šä¸ªåŒºåŸŸéšæœºï¼‰ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶")
    parser.add_argument("--areas", type=str, nargs="+", help="ç›®æ ‡åŒºåŸŸåˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶")
    parser.add_argument("--fixed-store", type=str, help="å›ºå®šç›®æ ‡storeï¼Œè¦†ç›–é…ç½®æ–‡ä»¶")
    parser.add_argument("--debug", action="store_true", help="å¼€å¯è°ƒè¯•æ¨¡å¼ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶log.debugï¼‰")
    args = parser.parse_args()

    try:
        # 1. å…ˆåŠ è½½æ—¥å¿—é…ç½®ï¼ˆç‹¬ç«‹äºå®Œæ•´é…ç½®ï¼‰
        log_file, debug = load_log_config_from_ini(args.config)
        if not log_file:
            sys.exit(1)
        # åº”ç”¨å‘½ä»¤è¡Œdebugå‚æ•°
        if args.debug:
            debug = True
        init_loggers(log_file, debug)

        # 2. åŠ è½½å®Œæ•´é…ç½®
        global_config = load_full_config(args.config, args)
        if not global_config:
            cleanup_resources()
            sys.exit(1)

        # 3. åŠ è½½Excelæ•°æ®
        location_list = load_xlsx_data(global_config.xlsx_path, global_config.sheet_name)
        if not location_list:
            console_logger.error("âŒ Excelæ— æœ‰æ•ˆæ•°æ®ï¼Œç¨‹åºé€€å‡º")
            cleanup_resources()
            sys.exit(1)

        # 4. åŒºåŸŸåˆ†ç»„ä¸éªŒè¯
        grouped_areas, valid_areas = group_and_validate_areas(location_list, global_config.areas)
        if not grouped_areas or not valid_areas:
            console_logger.error("âŒ åŒºåŸŸéªŒè¯å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            cleanup_resources()
            sys.exit(1)

        # 5. åˆå§‹åŒ–ä»»åŠ¡ç»Ÿè®¡
        task_stats.start_time = datetime.now()

        # 6. æ‰§è¡Œå¯¹åº”è§„åˆ™çš„ä»»åŠ¡
        if global_config.rule == 1:
            run_rule1(grouped_areas, valid_areas, global_config)
        else:
            run_rule2(grouped_areas, valid_areas, global_config)

        # 7. ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
        task_stats.end_time = datetime.now()
        print_final_report()

        # 8. æ¸…ç†èµ„æº
        cleanup_resources()

        # 9. é€€å‡ºçŠ¶æ€ç 
        if task_stats.continuous_failures >= MAX_CONTINUOUS_FAILURES:
            sys.exit(3)  # è¿ç»­å¤±è´¥é€€å‡º
        elif task_stats.fail > 0:
            sys.exit(2)  # æœ‰å¤±è´¥ä»»åŠ¡ä½†æœªè¾¾è¿ç»­é˜ˆå€¼
        else:
            sys.exit(0)  # å…¨éƒ¨æˆåŠŸ

    except Exception as e:
        console_logger.error(f"\nâŒ ç¨‹åºæ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
        if file_logger:
            file_logger.error("ç¨‹åºæ‰§è¡Œå¼‚å¸¸", exc_info=True)
        cleanup_resources()
        sys.exit(1)

if __name__ == "__main__":
    main()